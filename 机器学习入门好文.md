# 机器学习入门
### 机器学习的简易理解
#### 机器学习与传统计算机技术的区别
* 传统计算机：接收输入的指令，让计算机遵照指令执行。
* 机器学习：接收输入的数据，让计算机利用数据进行工作。
#### 机器学习的相关含义解释
* 机器学习方法：是计算机利用已有的数据，得出了某种模型，并利用此模型预测未来的一种方法。
* 机器学习主要目的：将人类思考归纳经验的过程转化为计算机通过对数据的处理计算得出模型的过程。
#### 机器学习的范围
* 机器学习与模式识别、统计学习、数据挖掘类似。并且机器学习与其他领域处理技术的结合形成了计算机视觉、语音识别、自然语言处理等交叉学科。
##### 模式识别
* 模式识别：模式识别=机器学习。前者源自工业界，后者源自计算机学科。
##### 数据挖掘
* 数据挖掘：机器学习+数据库。从数据中导出模式指引业务的改善，大部分数据挖掘算法是机器学习算法在数据库中的优化。
##### 统计学习
* 统计学习：统计学习近似等于机器学习，机器学习中的大多数方法来自统计学。
* 统计学习者关注的是统计模型的发展与优化，偏数学。
* 机器学习者更关注问题的解决，偏实践。
##### 计算机视觉
* 计算机视觉：图像处理+机器学习。图像处理技术用于将图像处理作为适合进入机器学习模型中的输入，机器学习则负责从图像中识别出相关的模式。
##### 语音识别
* 语音识别：语音处理+机器学习。语音识别就是音频处理技术与机器学习的结合。语音识别技术一般不会单独使用，一般会结合自然语言处理的相关技术。
##### 自然语言处理
* 自然语言处理：文本处理+机器学习。自然语言处理技术主要是让机器理解人类的语言。
* 在自然语言处理技术中，大量使用了编译原理相关的技术，例如词法分析，语法分析等，除此之外，在理解这个层面，则使用了语意理解、机器学习等技术。
#### 机器学习的方法
##### 回归算法
* 在大部分机器学习课程中，回归算法都是介绍的第一个算法。原因如下：
1. 回归算法比较简单，介绍它可以让人平滑地从统计学迁移到机器学习中。
2. 回归算法是后面若干强大算法的基石，如果不理解回归算法，则无法学习强大的算法。
* 线性回归：如何拟合出一条直线最佳匹配所有的数据。**梯度下降法** 是解决回归模型中最简单且有效的方法之一。
* 逻辑回归：逻辑回归属于分类算法。
* 逻辑回归与线性回归的区别：线性回归处理的是数值问题，最后逻辑回归属于分类算法。线性回归的预测结果是**数字**，逻辑回归的预测结果是**离散的分类**，逻辑回归只是对线性回归的计算结果加上了一个Sigmoid函数，将数值结果转化到了0到1之间的概率。
##### 神经网络
* 神经网络的诞生起源于对大脑工作机理的研究。早期生物界学者们使用神经网络来模拟大脑，机器学习的学者们使用神经网络进行机器学习的实验。BP算法诞生后，神经网络的发展进入热潮。
* 神经网络的学习机理：分解与整合。
* 神经网络的逻辑架构：在网络中分为输入层，隐藏层，输出层。输入层负责接收信号，隐藏层负责对数据的分解和处理，最后的结果被整合到输出层。每层中的一个圆代表了一个处理单元，可以认为是模拟了一个神经元，若干个处理单元组成了一个层，若干个层再组成一个网络，并被称为：神经网络。
* 处理单元：每个处理单元事实上就是一个逻辑回归模型，逻辑回归模型接收上层的输入，把模型的预测结果作为输出传输到下一个层次。通过这样的层次，神经网络可以完成非常复杂的非线性分类。
##### 支持向量机
* 支持向量机算法从某种意义上来说是逻辑回归算法的强化：通过给予逻辑回归算法更严格的优化条件，支持向量机算法可以获得比逻辑回归更好的分类界线。
* 支持向量机算法通过与高斯“核”结合，可以表达出非常复杂的分类界线，从而能够达到很好的分类效果。
* “核”事实上就是一种特殊的函数，最典型的特征就是可以将低维的空间映射到高维的空间。
* 支持向量机算法的核心步骤中，有一步证明，即将数据从低维映射到高维不会带来最后计算复杂性的提升。于是通过支持向量机算法既可以保持计算效率又能获得非常好的分类效果。
##### 无监督算法与有监督算法
* 之前的算法显著的特征就是训练的数据中包含了标签，训练出的模型可以对其他未知数据预测标签，这类算法被称为有监督算法。
* 当训练的数据都是不含标签的，并且算法的目的是通过训练，推测出这些数据的标签。这类算法有一个统称，即无监督算法，无监督算法中最典型的代表就是聚类算法。
##### 聚类算法
* 聚类算法就是计算种群中的距离，根据距离的远近将数据划分为多个族群。
* 聚类算法中最典型的代表就是K-Means算法。
##### 降维算法
* 降维算法也属于一种无监督学习算法，主要特征是将数据从高维降低到低维层次。维度主要指的是数据的特征量大小。
* 降维的例子：房价包含房子的长、宽、面积与房间数量四个特征，数据的维度为4，但长与宽实际上与面积表示的信息重叠，因此通过降维算法能够去除冗余信息，将特征量减少为面积与房间数量两个特征。
* 当数据可减少的维度肉眼不可视时，或者没有冗余的特征时，降维算法也能工作，不过这样会带来一些信息的损失。但是降维算法可从数学上证明，从高维压缩到低维中最大程度地保留了数据的信息，因此降维算法仍然有很多好处。
* 降维算法的主要作用：压缩数据与提升机器学习其他算法的效率。通过降维算法可将几千个特征的数据压缩至若干个特征。另外降维算法的另一个好处是数据的可视化，例如能够将5维的数据压缩至2维，再用二维平面来可视。降维算法的主要代表是PAC算法（主成分分析算法）。
##### 推荐算法
* 推荐算法的主要特征就是自动向用户推荐他们最感兴趣的东西。推荐算法有两个主要的类别：
1. 基于物品内容的推荐，将与用户购买的内容近似的物品推荐给用户，这样的前提是每个物品都得有若干个标签，因此才可以找出与用户购买物品类似的物品，这样推荐的好处是关联程度较大，但由于每个物品都要贴标签，因此工作量较大。
2. 基于用户相似度的推荐，则是将目标用户兴趣相同的其他用户购买的东西推荐给目标用户，例如小A历史上购买了物品B和C，经过算法分析，发现另一个与小A近似的用户小D购买了物品E，于是将物品E推荐给小A。
* 两类推荐算法都有各自的优缺点，在一般的电商应用中，通常是两类算法混合使用。推荐算法中最有名的算法就是**协同过滤算法**。
* 推荐算法既不属于监督学习算法也不属于非监督学习算法，是单独的一类算法。
##### 其他算法
* 机器学习界还有其他的如高斯判别、朴素贝叶斯，决策树等算法。
* 机器学习界的一个特色就是算法众多，发展百花齐放。
* 还有一些算法不属于机器学习领域，但经常出现在机器学习领域中。主要代表有：
1. 梯度下降法，主要运用在线性回归、逻辑回归，神经网络，推荐算法中；
2. 牛顿法，主要运用在线性回归中；
3. BP算法，主要运用在神经网络中；
4. SMO算法，主要运用在SVM中。
